{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "import io\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read all File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'C:/Users/gisel/Desktop/WF'\n",
    "category_list = [category for category in listdir(directory)]\n",
    "subcategory_name_list =[]\n",
    "dic = {}\n",
    "for category in category_list:\n",
    "    subcategories = [subcategory for subcategory in listdir(directory+'/'+category)]\n",
    "    subcategory_name = [s.replace('.csv','') for s in subcategories]\n",
    "    dic[category] = subcategory_name\n",
    "    subcategory_name_list.append(subcategory_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def freList(wf_path):\n",
    "    df_wf = pd.read_csv(wf_path)\n",
    "    fre_word = [i for i in df_wf.iloc[:,0][0:30]]\n",
    "    return fre_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tfidfList(tfidf_path, subcategory):\n",
    "    df_tfidf = pd.read_csv(tfidf_path, encoding = \"ISO-8859-1\")\n",
    "    df_tfidf = df_tfidf.sort_values(by=[subcategory],ascending=False)\n",
    "    \n",
    "    tfidf_word = [i for i in df_tfidf.loc[:,'word'][0:30]]\n",
    "    return tfidf_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matchwords(wf_path, tfidf_path, subcategory):\n",
    "    wf_word = freList(wf_path)\n",
    "    tfidf_word = tfidfList(tfidf_path, subcategory)\n",
    "    fre_tf_inter = list(set(wf_word).intersection(tfidf_word))\n",
    "    return fre_tf_inter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean RawTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import sent_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_sentence_csv(txt_path):\n",
    "    with open(txt_path, 'r') as RawTrain:\n",
    "        RawTrain = RawTrain.read()\n",
    "    \n",
    "        #split into sentences\n",
    "        text = unicodedata.normalize(\"NFKD\", RawTrain)\n",
    "        text = re.sub('\\\\n',' ',text)\n",
    "        sentences = sent_tokenize(text)\n",
    "        df_sent = pd.DataFrame(columns = ['No.','Sentence','StemWords','MatchWords'])\n",
    "        for n, sent in enumerate(sentences):\n",
    "            df_sent.loc[n, 'No.'] = n\n",
    "            df_sent.loc[n, 'Sentence'] = sent\n",
    "    \n",
    "        #Split into words\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        #Use Porter Stemmer \n",
    "        porter = nltk.PorterStemmer()\n",
    "    \n",
    "        stemWordsList = []\n",
    "        MatchWordsList = []\n",
    "        for n, sent in enumerate(sentences):\n",
    "            tokens = word_tokenize(sent)\n",
    "            words = [w.lower() for w in tokens if w.isalpha() if w.lower()not in stop_words]\n",
    "            stemwords = [porter.stem(w) for w in words]\n",
    "            stemWordsList.append(stemwords)\n",
    "\n",
    "            MatchWords = set(fre_tf_inter).intersection(stemwords)\n",
    "            MatchWordsList.append(MatchWords)\n",
    "\n",
    "        df_sent['StemWords']= stemWordsList   \n",
    "        df_sent['MatchWords']=MatchWordsList\n",
    "        df_sent['Use'] = np.where(df_sent['MatchWords'] == set(), 'N', 'Y')\n",
    "        return df_sent\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_sent_csv(txt_path,output_scv_path):\n",
    "    df_sent = Train_sentence_csv(txt_path)\n",
    "    df_sent.to_csv(output_scv_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ouput_useful_txt(txt_path, output_txt_path):\n",
    "    df_sent = Train_sentence_csv(txt_path)\n",
    "    useful_sent = df_sent.loc[df_sent['Use'] == 'Y']['Sentence']\n",
    "    \n",
    "    file = open(output_txt_path,'w', encoding = \"utf-8\") \n",
    "    sent = [i for i in useful_sent]\n",
    "    sent = '\\n'.join(sent)\n",
    "    file.write(sent) \n",
    "    file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ensure_dir(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 CAPACITY BUILDING AGENCY CERTIFICATION\n",
      "0 CAPACITY BUILDING MANPOWER DEVELOPMENT\n",
      "0 CAPACITY BUILDING PROFESSIONAL CERTIFICATION\n",
      "0 CAPACITY BUILDING STANDARDISATION DEVELOPMENT\n",
      "1 CHILD ONLINE PROTECTION INSTITUTIONAL SUPPORT\n",
      "1 CHILD ONLINE PROTECTION NATIONAL LEGISLATION\n",
      "1 CHILD ONLINE PROTECTION REPORTING MECHANISM\n",
      "1 CHILD ONLINE PROTECTION UN CONVENTION AND PROTOCOL\n",
      "2 COOPERATION INTERNATIONAL COOPERATION\n",
      "2 COOPERATION INTRA-AGENCY COOPERATION\n",
      "2 COOPERATION INTRA-STATE COOPERATION\n",
      "2 COOPERATION PUBLIC SECTOR PARTNERSHIP\n",
      "3 LEGAL MEASURES CRIMINAL LEGISLATION\n",
      "3 LEGAL MEASURES REGULATION AND COMPLIANCE\n",
      "4 ORGANIZATION MEASURES NATIONAL BENCHMARKING\n",
      "4 ORGANIZATION MEASURES POLICY\n",
      "4 ORGANIZATION MEASURES RESPONSIBLE AGENCY\n",
      "4 ORGANIZATION MEASURES ROADMAP FOR GOVERNANCE\n",
      "5 TECHNICAL MEASURES CERTIFICATION\n",
      "5 TECHNICAL MEASURES CIRT\n",
      "5 TECHNICAL MEASURES STANDARDS\n"
     ]
    }
   ],
   "source": [
    "txtpath_list=[]\n",
    "for n,category in enumerate(category_list):\n",
    "    for subcategory in dic[category_list[n]]:\n",
    "        wf_path = \"C:/Users/gisel/Desktop/WF/\" + category_list[n]+'/'+ subcategory+'.csv'\n",
    "        tfidf_path = \"C:/Users/gisel/Desktop/un crawl raw data/tfidf/\"+ category_list[n] + \" tfidf.csv\"\n",
    "        \n",
    "        \n",
    "        txt_path = \"C:/Users/gisel/Desktop/Cyber-master/Raw_Training_txt_combine/\"+ category_list[n]+'/'+ subcategory+'.txt'\n",
    "        txtpath_list.append(txt_path)\n",
    "        \n",
    "        output_scv_path = \"C:/Users/gisel/Desktop/Cyber-master/Training_clean_tf_wf/\"+ category_list[n]+'/'+ subcategory+'.csv'\n",
    "        output_txt_path = \"C:/Users/gisel/Desktop/Cyber-master/Training_clean_tf_wf/\"+ category_list[n]+'/'+ subcategory+'.txt'\n",
    "\n",
    "        directory = os.path.dirname(output_scv_path)\n",
    "\n",
    "        try:\n",
    "            os.stat(directory)\n",
    "        except:\n",
    "            os.mkdir(directory) \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        output_sent_csv(txt_path,output_scv_path)\n",
    "\n",
    "        \n",
    "        ouput_useful_txt(txt_path, output_txt_path)\n",
    "        print(n,category,subcategory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
